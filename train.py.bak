import random
import torch
import torch.nn as nn
from torch.autograd import Variable
from torch import optim
from config import MAX_LENGTH,MAX_SESSION,TERM_HIDDEN_SIZE,QUERY_HIDDEN_SIZE,SOS_token,EOS_token,MAX_DIC

import cPickle as pickle
S = pickle.load(open("./data/S.pkl","r"))
T = pickle.load(open("./data/T.pkl","r"))
D = pickle.load(open("./data/D.pkl","r"))

print S
print T
print D

use_cuda = torch.cuda.is_available()

from model import *
from Lang import prepareData

input_lang, output_lang, pairs = prepareData('eng', 'fra', True)
print(random.choice(pairs))

def indexesFromSentence(lang, sentence):
    return [lang.word2index[word] for word in sentence.split(' ')]

def variableFromSentence(lang, sentence):
    indexes = indexesFromSentence(lang, sentence)
    indexes.append(EOS_token)
    result = Variable(torch.LongTensor(indexes).view(-1, 1))
    if use_cuda:
        return result.cuda()
    else:
        return result

def variablesFromPair(pair):
    input_variable = variableFromSentence(input_lang, pair[0])
    target_variable = variableFromSentence(output_lang, pair[1])
    return (input_variable, target_variable)


import time
import math
def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)
def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))

def train(input_variable, target_variable, t_encoder, q_decoder, q_encoder, dense, t_encoder_optimizer, q_decoder_optimizer, q_encoder_optimizer, criterion, max_length=MAX_LENGTH):
    encoder_hidden = t_encoder.initHidden()
    q_encoder_hidden = q_encoder.initHidden()

    t_encoder_optimizer.zero_grad()
    q_decoder_optimizer.zero_grad()
    q_encoder_optimizer.zero_grad()

    input_length = input_variable.size()[0]
    target_length = target_variable.size()[0]

    loss = 0
    #query encoding
    q_encoder_outputs = Variable(torch.zeros(max_length, q_encoder.hidden_size))
    q_encoder_outputs = q_encoder_outputs.cuda() if use_cuda else q_encoder_outputs
    for qi in range(3): #for each query in session before

        #term encoding
        encoder_outputs = Variable(torch.zeros(max_length, t_encoder.hidden_size))
        encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs

        for ei in range(input_length):
            encoder_output, encoder_hidden = t_encoder(
                input_variable[ei], encoder_hidden)
            encoder_outputs[ei] = encoder_output[0][0]


        q_encoder_output, q_encoder_hidden = q_encoder(
            q_encoder_hidden, q_encoder_hidden)
        q_encoder_outputs[ei] = q_encoder_output[0][0]


    # query decoding
    decoder_input = Variable(torch.LongTensor([[SOS_token]]))
    decoder_input = decoder_input.cuda() if use_cuda else decoder_input

    #fully connected layer
    decoder_hidden = q_encoder_hidden

    for di in range(target_length):
        decoder_output, decoder_hidden, decoder_attention = q_decoder(
            decoder_input, decoder_hidden, q_encoder_outputs)
        topv, topi = decoder_output.data.topk(1)
        ni = topi[0][0]

        decoder_input = Variable(torch.LongTensor([[ni]]))
        decoder_input = decoder_input.cuda() if use_cuda else decoder_input

        loss += criterion(decoder_output, target_variable[di])
        if ni == EOS_token:
            break

    loss.backward()

    t_encoder_optimizer.step()
    q_decoder_optimizer.step()

    return loss.data[0] / target_length


from tqdm import tqdm
def trainIters(t_encoder, q_encoder, q_decoder, dense, n_iters, save_every=10000, print_every=1000, learning_rate=0.01):
    start = time.time()
    print_losses = []
    print_loss_total = 0


    t_encoder_optimizer = optim.SGD(t_encoder.parameters(), lr=learning_rate)
    q_encoder_optimizer = optim.SGD(q_encoder.parameters(), lr=learning_rate)
    q_decoder_optimizer = optim.SGD(q_decoder.parameters(), lr=learning_rate)
    dense_optimizer = optim.SGD(dense.parameters(),lr=learning_rate)

    training_pairs = [variablesFromPair(i)
                      for i in pairs]
    criterion = nn.NLLLoss()

    for iter in tqdm(range(1, len(training_pairs) + 1)):
        training_pair = training_pairs[iter - 1]
        input_variable = training_pair[0]
        target_variable = training_pair[1]

        loss = train(input_variable, target_variable, t_encoder, q_decoder, q_encoder, dense,
                     t_encoder_optimizer, q_decoder_optimizer, q_encoder_optimizer, criterion)
        print_loss_total += loss

        if iter % save_every == 0:
            torch.save(t_encoder.state_dict(), "model/%d.enc" % iter)
            torch.save(q_decoder.state_dict(), "model/%d.dec" % iter)

        if iter % print_every == 0:
            print print_loss_total / print_every, iter
            print_losses.append(print_loss_total / print_every)
            print_loss_total = 0

    showPlot(print_losses)

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np


def showPlot(points):
    plt.figure()
    fig, ax = plt.subplots()
    # this locator puts ticks at regular intervals
    loc = ticker.MultipleLocator(base=0.2)
    ax.yaxis.set_major_locator(loc)
    plt.plot(points)


t_encoder = TermEncoder(MAX_DIC, TERM_HIDDEN_SIZE)
q_encoder = QueryEncoder(TERM_HIDDEN_SIZE, QUERY_HIDDEN_SIZE)
q_decoder = QueryDecoder(QUERY_HIDDEN_SIZE, MAX_DIC,1, dropout_p=0.1)
dense = nn.Linear(QUERY_HIDDEN_SIZE,TERM_HIDDEN_SIZE)

if use_cuda:
    t_encoder = t_encoder.cuda()
    q_encoder = q_encoder.cuda()
    q_decoder = q_decoder.cuda()
    dense = dense.cuda()


for epoch in range(10):
    trainIters(t_encoder, q_encoder, q_decoder, dense, 75000,save_every=10000 ,print_every=1000)
    print("epoch %d#################"%epoch)